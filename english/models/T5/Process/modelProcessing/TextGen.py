import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
from transformers.modeling_outputs import BaseModelOutput

class TextGeneration:
    
    def __init__(self, model_name="t5-large"):
        # Táº£i mÃ´ hÃ¬nh vÃ  tokenizer T5
        self.tokenizer = T5Tokenizer.from_pretrained(model_name)
        self.model = T5ForConditionalGeneration.from_pretrained(model_name)

    def load_inputs(self, input_path):
        # Táº£i dá»¯ liá»‡u tá»« Decoder Layer (BaseModelOutput tá»« Encoder)
        self.inputs = torch.load(input_path)

        if isinstance(self.inputs, dict) and 'encoder_outputs' in self.inputs:
            print(" ÄÃ£ táº£i dá»¯ liá»‡u tá»« Encoder Layer (encoder_outputs, attention_mask, decoder_input_ids).")
            self.encoder_outputs = self.inputs['encoder_outputs']
            self.attention_mask = self.inputs['attention_mask']

            print("ğŸ”¸ Encoder Hidden States:", self.encoder_outputs.last_hidden_state[0, :7])
            print("ğŸ”¸ Attention Mask:", self.attention_mask[0, :7])
        else:
            raise ValueError("Dá»¯ liá»‡u khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng. Cáº§n chá»©a 'encoder_outputs'.")

    def _prepare_inputs(self):
        # Chuáº©n bá»‹ dá»¯ liá»‡u trÆ°á»›c khi sinh vÄƒn báº£n
        batch_size, seq_len, _ = self.encoder_outputs.last_hidden_state.shape

        if self.attention_mask.shape[0] != batch_size:
            repeat_factor = batch_size // self.attention_mask.shape[0]
            self.attention_mask = self.attention_mask.repeat(repeat_factor, 1)

        self.attention_mask = self.attention_mask.to(self.model.device)
        self.encoder_outputs = BaseModelOutput(
            last_hidden_state=self.encoder_outputs.last_hidden_state.to(self.model.device)
        )

    def generate_text(self, strategy="beam_search"):
        """
        Sinh vÄƒn báº£n theo chiáº¿n lÆ°á»£c tá»‘i Æ°u hÃ³a:
        - "default": Beam Search máº·c Ä‘á»‹nh (num_beams=5)
        - "greedy": Greedy Search (num_beams=1)
        - "beam_search": Beam Search (num_beams=1)
        - "top_k": Top-k Sampling (top_k=10)
        - "top_p": Top-p Sampling (top_p=0.5)
        """
        self._prepare_inputs()

        generation_config = {
            "encoder_outputs": self.encoder_outputs,
            "attention_mask": self.attention_mask,
            "max_length": 256,
            "min_length": 64,
            "length_penalty": 2.0,
        }

        file_name = "../object/TextGeneration/generated_"

        if strategy == "greedy":
            generation_config["num_beams"] = 1
            file_name += "greedy.pt"

        elif strategy == "beam_search":
            generation_config["num_beams"] = 1
            file_name += "beam_search.pt"

        elif strategy == "top_k":
            generation_config.update({"do_sample": True, "top_k": 10})
            generation_config["early_stopping"] = True
            file_name += "top_k.pt"

        elif strategy == "top_p":
            generation_config.update({"do_sample": True, "top_p": 0.5})
            generation_config["early_stopping"] = True
            file_name += "top_p.pt"

        else:
            file_name += "default.pt"

        # Sinh vÄƒn báº£n
        with torch.no_grad():
            generated_ids = self.model.generate(**generation_config)

        torch.save(generated_ids, file_name)
        print(f"ğŸ“‚ Token IDs Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o {file_name}")

        strategy_name = {
            "default": "Máº·c Ä‘á»‹nh - Beam Search",
            "greedy": "Greedy Search",
            "beam_search": "Beam Search (num_beams=1)",
            "top_k": "Top-k Sampling",
            "top_p": "Top-p Sampling"
        }
        print(f"\nToken IDs sinh ra ({strategy_name[strategy]}):\n{generated_ids[0]}")

def show_menu():
    print("\n===== CHá»ŒN PHÆ¯Æ NG PHÃP SINH VÄ‚N Báº¢N =====")
    print("1ï¸. Máº·c Ä‘á»‹nh (Beam Search)")
    print("2ï¸. Greedy Search")
    print("3ï¸. Beam Search (num_beams=1)")
    print("4ï¸. Top-k Sampling")
    print("5ï¸. Top-p Sampling")
    print("Nháº¥n phÃ­m báº¥t ká»³ Ä‘á»ƒ thoÃ¡t")
    print("=========================================")

if __name__ == "__main__":
    text_gen = TextGeneration()
    text_gen.load_inputs("../object/decoder_outputs_default.pt")

    while True:
        show_menu()
        choice = input("Nháº­p lá»±a chá»n (1-5): ")

        if choice == "1":
            text_gen.generate_text(strategy="default")
        elif choice == "2":
            text_gen.generate_text(strategy="greedy")
        elif choice == "3":
            text_gen.generate_text(strategy="beam_search")
        elif choice == "4":
            text_gen.generate_text(strategy="top_k")
        elif choice == "5":
            text_gen.generate_text(strategy="top_p")
        else:
            print("ThoÃ¡t chÆ°Æ¡ng trÃ¬nh. Táº¡m biá»‡t!")
            break
